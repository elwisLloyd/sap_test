{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hhwrV4CzOvvz"
   },
   "source": [
    "# Постановка задачи\n",
    "\n",
    "---\n",
    "В обучающих данных имеется 80 моторов, каждый из которых живет определенное число циклов. Каждый цикл происходит снятие информации с датчиков S1 – S21 и происходит переустановка настроечных параметров Setting1 – Setting2. \n",
    "\n",
    "Необходимо было провести анализ предоставленных данных по 80 моторам (файл Data_80.csv). Сделать предположение о выходе из строя мотора на основании имеющихся данных датчиков. Далее на основании дополнительно предоставленных данных по 20 моторам (файл Data_Add_20.csv) сделать предположения о выходе мотора из строя на следующем цикле.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U94-y28jRt5u"
   },
   "source": [
    "# Описание методов решения\n",
    "\n",
    "---\n",
    "\n",
    "Были использованы три подхода - логистическая регрессия, градиентный бустинг и рекуррентная нейронная сеть. Первые два были реализованы с помощью библиотеки sklearn, рекуррентная нейронная сеть с помощью библиотеки keras. \n",
    "\n",
    "С каждым из подходов было попробовано использовать в качестве признаков показания датчиков на предыдущем этапе работы цикла, и было получено наибольшее число эпох, которое можно использовать - 2 для логистической регрессии и градиентного буcтинга, 10 - для рекуррентной нейронной сети. \n",
    "\n",
    "Для каждого из типов алгоритмов были подобраны наилучшие параметры: \n",
    "\n",
    "для логистической регрессии:\n",
    "- параметр L2-регуляризации;\n",
    "\n",
    "для градиентного бустинга:\n",
    "- коэффициент скорости обучения, \n",
    "- подвыборка, \n",
    "- число бустеров,\n",
    "- максимальная глубина,\n",
    "- максимальное число признаков;\n",
    "\n",
    "для рекуррентной сети:\n",
    "- количество юнитов в GRU. \n",
    "\n",
    "Для логистической регрессии и градиентного бустинга параметры подбирались автоматически с помощью библиотеки scikit-optimize. \n",
    "\n",
    "Лучше всего среди классификаторов себя показала логистическая регрессия с глубиной 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UD3pKWPMVHaq"
   },
   "source": [
    "# Результаты\n",
    "\n",
    "---\n",
    "**Результат с логистической регрессией:**\n",
    "  - precision = 0.888889;\n",
    "  - recall    = 0.400000;\n",
    "  - F1        = 0.551724.\n",
    "  \n",
    "**Результат с градиентным бустингом:**\n",
    "  - precision = 0.750000;\n",
    "  - recall    = 0.300000;\n",
    "  - F1        = 0.428571.\n",
    "  \n",
    "**Результат с рекуррентной нейронной сетью:**\n",
    "  - precision = 0.500000;\n",
    "  - recall    = 0.250000;\n",
    "  - F1        = 0.333333;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "colab_type": "code",
    "id": "YtrP6I1xqHxQ",
    "outputId": "2cf91707-4d32-43b7-cabd-4b8f5aceef7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0f3fb5b128>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data={\"model\": ['logreg', 'gradient boosting', 'rnn'], 'f1-score': [0.55, 0.43, 0.33], 'precision': [0.88, 0.75, 0.5], 'recall': [0.4, 0.3, 0.25]})\n",
    "df.plot.line(x='model', y=['f1-score', 'precision', 'recall'], figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nhN2MSl8kyoc"
   },
   "source": [
    "\n",
    "# Код\n",
    "\n",
    "---\n",
    "\n",
    "Визуализируем показания датчиков для одного из двигателей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "colab_type": "code",
    "id": "ffLeEQnhaiP3",
    "outputId": "1f328276-c533-4bda-afa6-5d0edaf1820b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/tf_bayesian/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/user/tf_bayesian/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0f3dac92e8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv('Data_80.csv', sep=';')\n",
    "df = data[data[\"id\"]=='Engine_1']\n",
    "columns = list(df)\n",
    "del columns[0]\n",
    "del columns [0]\n",
    "for name in columns:\n",
    "  try:\n",
    "      df[name] = df[name].str.replace(',', '.')\n",
    "      df[name] = df[name].astype(float)\n",
    "  except:\n",
    "      continue\n",
    "df.plot.line(x='cycle', y=columns, figsize = (15, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TcmoJP38oEIz"
   },
   "source": [
    "Визуально нельзя сделать выводы о поведении показателей в моменты времени, предшествующие поломке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "colab_type": "code",
    "id": "xrB49NbxOu01",
    "outputId": "54e0470d-875b-4d77-9c52-048ca2b8ba44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-optimize in /home/user/tf_bayesian/lib/python3.6/site-packages (0.5.2)\n",
      "Requirement already satisfied: numpy in /home/user/tf_bayesian/lib/python3.6/site-packages (from scikit-optimize) (1.16.2)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /home/user/tf_bayesian/lib/python3.6/site-packages (from scikit-optimize) (1.2.1)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /home/user/tf_bayesian/lib/python3.6/site-packages (from scikit-optimize) (0.20.3)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: eli5 in /home/user/tf_bayesian/lib/python3.6/site-packages (0.8.2)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/user/tf_bayesian/lib/python3.6/site-packages (from eli5) (1.16.2)\n",
      "Requirement already satisfied: graphviz in /home/user/tf_bayesian/lib/python3.6/site-packages (from eli5) (0.10.1)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /home/user/tf_bayesian/lib/python3.6/site-packages (from eli5) (0.8.3)\n",
      "Requirement already satisfied: scipy in /home/user/tf_bayesian/lib/python3.6/site-packages (from eli5) (1.2.1)\n",
      "Requirement already satisfied: six in /home/user/tf_bayesian/lib/python3.6/site-packages (from eli5) (1.12.0)\n",
      "Requirement already satisfied: attrs>16.0.0 in /home/user/tf_bayesian/lib/python3.6/site-packages (from eli5) (19.1.0)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /home/user/tf_bayesian/lib/python3.6/site-packages (from eli5) (0.20.3)\n",
      "Requirement already satisfied: typing in /home/user/tf_bayesian/lib/python3.6/site-packages (from eli5) (3.6.6)\n",
      "Requirement already satisfied: jinja2 in /home/user/tf_bayesian/lib/python3.6/site-packages (from eli5) (2.10.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/user/tf_bayesian/lib/python3.6/site-packages (from jinja2->eli5) (1.1.1)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-optimize\n",
    "!pip install eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gYwKKEXmL-_f",
    "outputId": "11523a35-c2fd-4c99-f85e-e5f83325adcd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import copy\n",
    "import csv\n",
    "import random\n",
    "import tempfile\n",
    "import os\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.layers import Input, GRU, Dense\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9xGSXmwOpZPA"
   },
   "source": [
    "Открытие данных для обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PNxxZyNfMB4Y"
   },
   "outputs": [],
   "source": [
    "\n",
    "def read_training_data(file_name: str) -> Tuple[np.ndarray, np.ndarray, List[str]]:\n",
    "    \"\"\"\n",
    "    Скачиваем обучающие данные в виде матрицы входных сигналов X и вектора желаемых выходов y.\n",
    "    X - это вещественная numpy-матрица из N строк и 23 столбцов (по числу признаков).\n",
    "    y - это целочисленный вектор из нулей и единиц (0 - мотор не выйдет из строя после текущего цикла работы, а\n",
    "    1 - наоборот, выйдет).\n",
    "    В случае, если что-то пошло не так (например, данные в неверном формате), то кидаем ValueError.\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(file_name):\n",
    "        raise ValueError('File `{0}` does not exist!'.format(file_name))\n",
    "    true_header = ['id', 'cycle', 's1', 's10', 's11', 's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's2',\n",
    "                   's20', 's21', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 'setting1', 'setting2']\n",
    "    X = []\n",
    "    y = []\n",
    "    loaded_header = None\n",
    "    line_idx = 1\n",
    "    cycle = 0\n",
    "    engine = None\n",
    "    with codecs.open(file_name, mode='r', encoding='utf-8', errors='ignore') as fp:\n",
    "        reader = csv.reader(fp, quotechar='\"', delimiter =';')\n",
    "        for row in reader:\n",
    "            prep = list(map(lambda it: it.strip(), row))\n",
    "            if len(prep) > 0:\n",
    "                err_msg = 'File `{0}`: line {1} is wrong!'.format(file_name, line_idx)\n",
    "                if loaded_header is None:\n",
    "                    loaded_header = copy.copy(prep)\n",
    "                    if loaded_header != true_header:\n",
    "                        raise ValueError(err_msg)\n",
    "                else:\n",
    "                    if len(prep) != len(loaded_header):\n",
    "                        raise ValueError(err_msg)\n",
    "                    if not prep[0].startswith('Engine_'):\n",
    "                        raise ValueError(err_msg)\n",
    "                    new_cycle = int(prep[1])\n",
    "                    if engine is None:\n",
    "                        engine = prep[0]\n",
    "                        cycle = 1\n",
    "                    else:\n",
    "                        if engine == prep[0]:\n",
    "                            cycle += 1\n",
    "                        else:\n",
    "                            engine = prep[0]\n",
    "                            y += [0 for _ in range(cycle - 1)]\n",
    "                            y.append(1)\n",
    "                            cycle = 1\n",
    "                    if cycle != new_cycle:\n",
    "                        raise ValueError(err_msg)\n",
    "                    X.append([float(val.replace(',', '.')) for val in prep[2:]])\n",
    "            line_idx += 1\n",
    "    if cycle > 0:\n",
    "        y += [0 for _ in range(cycle - 1)]\n",
    "        y.append(1)\n",
    "    return np.array(X, dtype=np.float64), np.array(y, dtype=np.int32), true_header[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "15ytZiw3pd5J"
   },
   "source": [
    "Открытие данных для тестирования модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4U53vwPIMH8i"
   },
   "outputs": [],
   "source": [
    "def read_test_data(file_name: str) -> Tuple[np.ndarray, np.ndarray, List[str]]:\n",
    "    \"\"\"\n",
    "    Скачиваем тестовые данные в виде матрицы входных сигналов X и вектора желаемых выходов y.\n",
    "    X - это вещественная numpy-матрица из N строк и 23 столбцов (по числу признаков).\n",
    "    y - это целочисленный вектор из нулей и единиц (0 - мотор не выйдет из строя после текущего цикла работы, а\n",
    "    1 - наоборот, выйдет).\n",
    "    В случае, если что-то пошло не так (например, данные в неверном формате), то кидаем ValueError.\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(file_name):\n",
    "        raise ValueError('File `{0}` does not exist!'.format(file_name))\n",
    "    true_header = ['id', 'cycle', 's1', 's10', 's11', 's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's2',\n",
    "                   's20', 's21', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 'setting1', 'setting2', 'Brake']\n",
    "    X = []\n",
    "    y = []\n",
    "    loaded_header = None\n",
    "    line_idx = 1\n",
    "    cycle = 0\n",
    "    engine = None\n",
    "    with codecs.open(file_name, mode='r', encoding='utf-8', errors='ignore') as fp:\n",
    "        reader = csv.reader(fp, quotechar='\"', delimiter =';')\n",
    "        for row in reader:\n",
    "            prep = list(map(lambda it: it.strip(), row))\n",
    "            if len(prep) > 0:\n",
    "                err_msg = 'File `{0}`: line {1} is wrong!'.format(file_name, line_idx)\n",
    "                if loaded_header is None:\n",
    "                    loaded_header = copy.copy(prep)\n",
    "                    if loaded_header != true_header:\n",
    "                        raise ValueError(err_msg)\n",
    "                else:\n",
    "                    if len(prep) != len(loaded_header):\n",
    "                        raise ValueError(err_msg)\n",
    "                    if not prep[0].startswith('Engine_'):\n",
    "                        raise ValueError(err_msg)\n",
    "                    new_cycle = int(prep[1])\n",
    "                    if engine is None:\n",
    "                        engine = prep[0]\n",
    "                        cycle = 1\n",
    "                    else:\n",
    "                        if engine == prep[0]:\n",
    "                            cycle += 1\n",
    "                        else:\n",
    "                            engine = prep[0]\n",
    "                            y += [0 for _ in range(cycle - 1)]\n",
    "                            y.append(1)\n",
    "                            cycle = 1\n",
    "                    if cycle != new_cycle:\n",
    "                        raise ValueError(err_msg)\n",
    "                    X.append([float(val.replace(',', '.')) for val in prep[2:-1]])\n",
    "            line_idx += 1\n",
    "    if cycle > 0:\n",
    "        y += [0 for _ in range(cycle - 1)]\n",
    "        y.append(1)\n",
    "    return np.array(X, dtype=np.float64), np.array(y, dtype=np.int32), true_header[2:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RN0uc3ECpjxE"
   },
   "source": [
    "Векторизация предыдущих состояний двигателя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lUMYim4fMVS1"
   },
   "outputs": [],
   "source": [
    "def apply_history(X: np.ndarray, y: np.ndarray, feature_names: List[str], n_history: int) -> \\\n",
    "        Tuple[np.ndarray, np.ndarray, List[str]]:\n",
    "    if n_history < 2:\n",
    "        return X, y, feature_names\n",
    "    bounds = []\n",
    "    start_idx = 0\n",
    "    for sample_idx in range(X.shape[0]):\n",
    "        if y[sample_idx] > 0:\n",
    "            if sample_idx == start_idx:\n",
    "                raise ValueError('Sample {0} is wrong!'.format(sample_idx))\n",
    "            if (sample_idx - start_idx + 1) < n_history:\n",
    "                raise ValueError('{0} is too large value for history!'.format(n_history))\n",
    "            bounds.append((start_idx, sample_idx + 1))\n",
    "            start_idx = sample_idx + 1\n",
    "    sample_idx = X.shape[0]\n",
    "    if (sample_idx - start_idx) > 0:\n",
    "        if (sample_idx - start_idx + 1) < n_history:\n",
    "            raise ValueError('{0} is too large value for history!'.format(n_history))\n",
    "        bounds.append((start_idx, sample_idx))\n",
    "    X_ = []\n",
    "    y_ = []\n",
    "    for cur_bounds in bounds:\n",
    "        start_idx = cur_bounds[0]\n",
    "        end_idx = start_idx + n_history\n",
    "        for _ in range(n_history - 1, cur_bounds[1] - cur_bounds[0]):\n",
    "            X_.append(np.reshape(X[start_idx:end_idx], newshape=(n_history * X.shape[1],)))\n",
    "            y_.append(y[end_idx - 1])\n",
    "            start_idx += 1\n",
    "            end_idx += 1\n",
    "    new_feature_names = []\n",
    "    for depth in range(2, n_history + 1):\n",
    "        new_feature_names += ['{0}[{1}-{2}]'.format(cur, depth - n_history, depth - n_history - 1)\n",
    "                              for cur in feature_names]\n",
    "    for depth in range(1, n_history + 1):\n",
    "        new_feature_names += ['{0}[{1}]'.format(cur, depth - n_history) for cur in feature_names]\n",
    "    return np.array(X_, dtype=np.float64), np.array(y_, dtype=np.int32), new_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BcKBUeC8MV_I"
   },
   "outputs": [],
   "source": [
    "def find_best_threshold(y_true: np.ndarray, predicted_probas: np.ndarray) -> float:\n",
    "    best_threshold = 1e-4\n",
    "    y_pred = np.asarray(predicted_probas >= best_threshold, dtype=np.int32)\n",
    "    best_f1 = f1_score(y_true, y_pred)\n",
    "    threshold = best_threshold + 1e-4\n",
    "    del y_pred\n",
    "    while threshold <= 1.0:\n",
    "        y_pred = np.asarray(predicted_probas >= threshold, dtype=np.int32)\n",
    "        new_f1 = f1_score(y_true, y_pred)\n",
    "        if new_f1 > best_f1:\n",
    "            best_threshold = threshold\n",
    "            best_f1 = new_f1\n",
    "        del y_pred\n",
    "        threshold += 1e-4\n",
    "    print('Best threshold is {0:.4f}.'.format(best_threshold))\n",
    "    print('Best F1 is {0:.6f}.'.format(best_f1))\n",
    "    return best_threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0cySQHCEpsLw"
   },
   "source": [
    "Обучение градиентного бустинга с подбором параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i2CI81FkMeq1"
   },
   "outputs": [],
   "source": [
    "def train_gradboost(X_train: np.ndarray, y_train: np.ndarray, random_state: int) -> Tuple[Pipeline, float]:\n",
    "    cv = BayesSearchCV(\n",
    "        estimator=Pipeline(steps=[\n",
    "            ('selector', VarianceThreshold(threshold=1e-5)),\n",
    "            ('cls', GradientBoostingClassifier(random_state=random_state, verbose=True, n_iter_no_change=None))\n",
    "        ]),\n",
    "        search_spaces={'cls__learning_rate': Real(1e-4, 1e-1, prior='log-uniform'),\n",
    "                       'cls__subsample': Real(0.5, 1.0, prior='uniform'),\n",
    "                       'cls__n_estimators': Integer(50, 2000), 'cls__max_depth': Integer(3, 10),\n",
    "                       'cls__max_features': Categorical(categories=['sqrt', 'log2', None])},\n",
    "        cv=5, n_iter=50, n_jobs=-1, scoring='roc_auc', refit=False, random_state=random_state, verbose=True\n",
    "    )\n",
    "    cv.fit(X_train, y_train)\n",
    "    print('')\n",
    "    print('Best ROC-AUC is {0:.6f}.'.format(cv.best_score_))\n",
    "    print('Best learning rate is {0:.6f}.'.format(cv.best_params_['cls__learning_rate']))\n",
    "    print('Best subsample value is {0:.6f}.'.format(cv.best_params_['cls__subsample']))\n",
    "    print('Best number of estimators is {0}.'.format(cv.best_params_['cls__n_estimators']))\n",
    "    print('Best maximal depth of the individual estimators is {0}.'.format(cv.best_params_['cls__max_depth']))\n",
    "    print('Best way of maximal features calculation is {0}.'.format(cv.best_params_['cls__max_features']))\n",
    "    print('')\n",
    "    probabilities = cross_val_predict(\n",
    "        estimator=Pipeline(steps=[\n",
    "            ('selector', VarianceThreshold(threshold=1e-5)),\n",
    "            ('cls', GradientBoostingClassifier(random_state=random_state, verbose=True, n_iter_no_change=None,\n",
    "                                               learning_rate=cv.best_params_['cls__learning_rate'],\n",
    "                                               subsample=cv.best_params_['cls__subsample'],\n",
    "                                               n_estimators=cv.best_params_['cls__n_estimators'],\n",
    "                                               max_depth=cv.best_params_['cls__max_depth'],\n",
    "                                               max_features=cv.best_params_['cls__max_features']))\n",
    "        ]),\n",
    "        X=X_train, y=y_train, cv=5, n_jobs=1, method='predict_proba'\n",
    "    )[:, 1]\n",
    "    threshold = find_best_threshold(y_train, probabilities)\n",
    "    print('')\n",
    "    cls = Pipeline(steps=[\n",
    "        ('selector', VarianceThreshold(threshold=1e-5)),\n",
    "        ('cls', GradientBoostingClassifier(random_state=random_state, verbose=True, n_iter_no_change=None,\n",
    "                                           learning_rate=cv.best_params_['cls__learning_rate'],\n",
    "                                           subsample=cv.best_params_['cls__subsample'],\n",
    "                                           n_estimators=cv.best_params_['cls__n_estimators'],\n",
    "                                           max_depth=cv.best_params_['cls__max_depth'],\n",
    "                                           max_features=cv.best_params_['cls__max_features']))\n",
    "    ])\n",
    "    cls.fit(X_train, y_train)\n",
    "    return cls, threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TnK6G3NzpvoX"
   },
   "source": [
    "Обучение логистической регрессии с подбором параметра"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NWicWck0MuZn"
   },
   "outputs": [],
   "source": [
    "def train_logreg(X_train: np.ndarray, y_train: np.ndarray, random_state: int) -> Tuple[Pipeline, float]:\n",
    "    cv = BayesSearchCV(\n",
    "        estimator=Pipeline(steps=[\n",
    "            ('mean', StandardScaler(with_mean=True, with_std=False, copy=True)),\n",
    "            ('selector', VarianceThreshold(threshold=1e-5)),\n",
    "            ('pca', PCA(whiten=True, random_state=random_state)),\n",
    "            ('cls', LogisticRegression(penalty='l2', solver='liblinear'))\n",
    "        ]),\n",
    "        search_spaces={'cls__C': Real(1e-2, 1e+3, prior='log-uniform')},\n",
    "        cv=5, n_iter=50, n_jobs=-1, scoring='roc_auc', refit=False, random_state=random_state, verbose=True\n",
    "    )\n",
    "    cv.fit(X_train, y_train)\n",
    "    print('')\n",
    "    print('Best ROC-AUC is {0:.6f}.'.format(cv.best_score_))\n",
    "    print('Best C is {0:.6f}.'.format(cv.best_params_['cls__C']))\n",
    "    print('')\n",
    "    probabilities = cross_val_predict(\n",
    "        estimator=Pipeline(steps=[\n",
    "            ('mean', StandardScaler(with_mean=True, with_std=False, copy=True)),\n",
    "            ('selector', VarianceThreshold(threshold=1e-5)),\n",
    "            ('pca', PCA(whiten=True, random_state=random_state)),\n",
    "            ('cls', LogisticRegression(penalty='l2', solver='liblinear', C=cv.best_params_['cls__C']))\n",
    "        ]),\n",
    "        X=X_train, y=y_train, cv=5, n_jobs=1, method='predict_proba'\n",
    "    )[:, 1]\n",
    "    threshold = find_best_threshold(y_train, probabilities)\n",
    "    print('')\n",
    "    cls = Pipeline(steps=[\n",
    "        ('mean', StandardScaler(with_mean=True, with_std=False, copy=True)),\n",
    "        ('selector', VarianceThreshold(threshold=1e-5)),\n",
    "        ('pca', PCA(whiten=True, random_state=random_state)),\n",
    "        ('cls', LogisticRegression(penalty='l2', solver='liblinear', C=cv.best_params_['cls__C']))\n",
    "    ])\n",
    "    cls.fit(X_train, y_train)\n",
    "    return cls, threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VLht-DEfpyiX"
   },
   "source": [
    "Функция для отображения результата"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j_8n_oH7Mxr2"
   },
   "outputs": [],
   "source": [
    "def evaluate_classifier(X_test: np.ndarray, y_test: np.ndarray, cls: Pipeline, threshold: float):\n",
    "    y_pred = np.asarray(cls.predict_proba(X_test)[:, 1] >= threshold, dtype=np.int32)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print('Final quality is:')\n",
    "    print('  - precision = {0:8.6f};'.format(precision))\n",
    "    print('  - recall    = {0:8.6f};'.format(recall))\n",
    "    print('  - F1        = {0:8.6f};'.format(f1))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HL1gXxMBM1KS"
   },
   "outputs": [],
   "source": [
    "train_file_name = 'Data_80.csv'\n",
    "test_file_name = 'Data_Add_20.csv'\n",
    "history = 2\n",
    "X_train, y_train, features = read_training_data(train_file_name)\n",
    "assert not np.any(np.isnan(X_train))\n",
    "assert set(y_train.tolist()) == {0, 1}\n",
    "X_test, y_test, features_ = read_test_data(test_file_name)\n",
    "assert not np.any(np.isnan(X_test))\n",
    "assert set(y_test.tolist()) == {0, 1}\n",
    "if features != features_:\n",
    "  raise ValueError('Features for training do not correspond to test features!')\n",
    "X_train, y_train, features = apply_history(X_train, y_train, features, history)\n",
    "X_test, y_test, features_ = apply_history(X_test, y_test, features_, history)\n",
    "assert not np.any(np.isnan(X_train))\n",
    "assert set(y_train.tolist()) == {0, 1}\n",
    "assert not np.any(np.isnan(X_test))\n",
    "assert set(y_test.tolist()) == {0, 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124748
    },
    "colab_type": "code",
    "id": "5NmHoCLON6Jb",
    "outputId": "2433fac6-dc76-406d-990b-ffe4bbf056a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.0min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   11.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   25.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   20.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   12.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   10.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   27.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   42.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   15.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   56.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   20.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   16.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   26.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   49.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    5.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   19.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   54.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   10.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   55.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   14.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    6.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   20.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   16.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   12.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   30.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   34.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  4.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   28.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   51.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   30.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best ROC-AUC is 0.994864.\n",
      "Best learning rate is 0.000127.\n",
      "Best subsample value is 0.500000.\n",
      "Best number of estimators is 1159.\n",
      "Best maximal depth of the individual estimators is 6.\n",
      "Best way of maximal features calculation is log2.\n",
      "\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.0642           0.0001            8.81s\n",
      "         2           0.0625           0.0001            9.23s\n",
      "         3           0.0558           0.0001            8.61s\n",
      "         4           0.0687           0.0001            8.65s\n",
      "         5           0.0506           0.0000            8.52s\n",
      "         6           0.0620           0.0000            8.20s\n",
      "         7           0.0537           0.0000            8.00s\n",
      "         8           0.0619           0.0000            8.07s\n",
      "         9           0.0505           0.0000            8.15s\n",
      "        10           0.0536           0.0000            8.17s\n",
      "        20           0.0670           0.0000            8.28s\n",
      "        30           0.0519           0.0000            8.24s\n",
      "        40           0.0573           0.0001            8.29s\n",
      "        50           0.0700           0.0000            8.32s\n",
      "        60           0.0512           0.0000            8.49s\n",
      "        70           0.0448           0.0000            8.82s\n",
      "        80           0.0541           0.0000            9.03s\n",
      "        90           0.0581           0.0000            9.28s\n",
      "       100           0.0560           0.0000            9.48s\n",
      "       200           0.0551           0.0000            9.52s\n",
      "       300           0.0527           0.0000            8.18s\n",
      "       400           0.0427           0.0000            7.40s\n",
      "       500           0.0530           0.0000            6.64s\n",
      "       600           0.0365           0.0000            5.79s\n",
      "       700           0.0344           0.0000            4.87s\n",
      "       800           0.0380           0.0000            3.87s\n",
      "       900           0.0339           0.0000            2.82s\n",
      "      1000           0.0358           0.0000            1.75s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.0675           0.0000           13.39s\n",
      "         2           0.0576           0.0001           13.72s\n",
      "         3           0.0607           0.0001           12.68s\n",
      "         4           0.0687           0.0001           13.05s\n",
      "         5           0.0572           0.0000           13.18s\n",
      "         6           0.0636           0.0000           13.10s\n",
      "         7           0.0490           0.0001           12.65s\n",
      "         8           0.0620           0.0000           12.33s\n",
      "         9           0.0585           0.0001           12.29s\n",
      "        10           0.0535           0.0001           12.31s\n",
      "        20           0.0639           0.0000           12.52s\n",
      "        30           0.0504           0.0000           12.25s\n",
      "        40           0.0589           0.0000           12.04s\n",
      "        50           0.0655           0.0000           11.98s\n",
      "        60           0.0529           0.0000           11.93s\n",
      "        70           0.0462           0.0000           11.95s\n",
      "        80           0.0573           0.0000           12.01s\n",
      "        90           0.0556           0.0000           12.01s\n",
      "       100           0.0520           0.0000           11.93s\n",
      "       200           0.0504           0.0000           10.88s\n",
      "       300           0.0507           0.0000            9.93s\n",
      "       400           0.0474           0.0000            8.64s\n",
      "       500           0.0479           0.0000            7.50s\n",
      "       600           0.0376           0.0000            6.23s\n",
      "       700           0.0398           0.0000            4.94s\n",
      "       800           0.0363           0.0000            3.76s\n",
      "       900           0.0335           0.0000            2.66s\n",
      "      1000           0.0359           0.0000            1.60s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.0560           0.0000            9.60s\n",
      "         2           0.0625           0.0001            9.46s\n",
      "         3           0.0672           0.0001            9.07s\n",
      "         4           0.0622           0.0001            8.77s\n",
      "         5           0.0620           0.0001            9.37s\n",
      "         6           0.0603           0.0000            9.12s\n",
      "         7           0.0619           0.0000            9.25s\n",
      "         8           0.0537           0.0001            9.48s\n",
      "         9           0.0665           0.0000            9.56s\n",
      "        10           0.0599           0.0000            9.69s\n",
      "        20           0.0638           0.0000            9.83s\n",
      "        30           0.0611           0.0000            9.90s\n",
      "        40           0.0588           0.0000            9.87s\n",
      "        50           0.0670           0.0000            9.70s\n",
      "        60           0.0531           0.0001            9.70s\n",
      "        70           0.0563           0.0000            9.69s\n",
      "        80           0.0530           0.0000            9.61s\n",
      "        90           0.0582           0.0000            9.56s\n",
      "       100           0.0503           0.0000            9.53s\n",
      "       200           0.0508           0.0000            8.89s\n",
      "       300           0.0448           0.0000            8.15s\n",
      "       400           0.0436           0.0000            7.66s\n",
      "       500           0.0446           0.0000            6.91s\n",
      "       600           0.0385           0.0000            5.76s\n",
      "       700           0.0417           0.0000            4.68s\n",
      "       800           0.0369           0.0000            3.63s\n",
      "       900           0.0330           0.0000            2.60s\n",
      "      1000           0.0334           0.0000            1.61s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.0593           0.0001           10.06s\n",
      "         2           0.0658           0.0001            9.04s\n",
      "         3           0.0608           0.0001            9.31s\n",
      "         4           0.0655           0.0000            9.34s\n",
      "         5           0.0605           0.0001            9.28s\n",
      "         6           0.0783           0.0001            9.41s\n",
      "         7           0.0700           0.0000            9.42s\n",
      "         8           0.0585           0.0001            9.54s\n",
      "         9           0.0713           0.0001            9.47s\n",
      "        10           0.0566           0.0001            9.42s\n",
      "        20           0.0621           0.0001            9.08s\n",
      "        30           0.0516           0.0001            9.14s\n",
      "        40           0.0510           0.0000            8.96s\n",
      "        50           0.0548           0.0000            8.87s\n",
      "        60           0.0584           0.0000            8.81s\n",
      "        70           0.0580           0.0000            8.75s\n",
      "        80           0.0517           0.0000            8.65s\n",
      "        90           0.0536           0.0000            8.61s\n",
      "       100           0.0488           0.0000            8.57s\n",
      "       200           0.0488           0.0000            7.76s\n",
      "       300           0.0432           0.0000            6.99s\n",
      "       400           0.0451           0.0000            6.21s\n",
      "       500           0.0435           0.0000            5.40s\n",
      "       600           0.0361           0.0000            4.80s\n",
      "       700           0.0399           0.0000            4.17s\n",
      "       800           0.0362           0.0000            3.38s\n",
      "       900           0.0327           0.0000            2.50s\n",
      "      1000           0.0374           0.0000            1.56s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.0576           0.0000           14.59s\n",
      "         2           0.0674           0.0001           15.12s\n",
      "         3           0.0656           0.0000           13.97s\n",
      "         4           0.0606           0.0001           14.17s\n",
      "         5           0.0654           0.0001           13.79s\n",
      "         6           0.0766           0.0001           13.77s\n",
      "         7           0.0715           0.0001           13.64s\n",
      "         8           0.0568           0.0001           13.56s\n",
      "         9           0.0696           0.0000           13.59s\n",
      "        10           0.0566           0.0001           13.44s\n",
      "        20           0.0604           0.0000           12.94s\n",
      "        30           0.0593           0.0000           12.84s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        40           0.0557           0.0000           12.86s\n",
      "        50           0.0546           0.0000           12.77s\n",
      "        60           0.0629           0.0000           12.60s\n",
      "        70           0.0520           0.0000           12.35s\n",
      "        80           0.0601           0.0000           12.25s\n",
      "        90           0.0495           0.0000           12.05s\n",
      "       100           0.0503           0.0000           11.85s\n",
      "       200           0.0409           0.0000           10.69s\n",
      "       300           0.0457           0.0000            9.56s\n",
      "       400           0.0471           0.0000            8.44s\n",
      "       500           0.0464           0.0000            7.04s\n",
      "       600           0.0379           0.0000            5.77s\n",
      "       700           0.0380           0.0000            4.63s\n",
      "       800           0.0369           0.0000            3.60s\n",
      "       900           0.0298           0.0000            2.58s\n",
      "      1000           0.0356           0.0000            1.58s\n",
      "Best threshold is 0.0164.\n",
      "Best F1 is 0.522613.\n",
      "\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.0586           0.0000           15.72s\n",
      "         2           0.0546           0.0000           14.15s\n",
      "         3           0.0676           0.0001           15.03s\n",
      "         4           0.0583           0.0001           14.58s\n",
      "         5           0.0582           0.0001           14.24s\n",
      "         6           0.0607           0.0001           14.23s\n",
      "         7           0.0541           0.0000           14.42s\n",
      "         8           0.0566           0.0001           14.51s\n",
      "         9           0.0552           0.0001           14.67s\n",
      "        10           0.0603           0.0000           14.64s\n",
      "        20           0.0606           0.0000           14.88s\n",
      "        30           0.0609           0.0001           14.71s\n",
      "        40           0.0565           0.0000           14.63s\n",
      "        50           0.0568           0.0000           14.35s\n",
      "        60           0.0692           0.0000           14.34s\n",
      "        70           0.0587           0.0000           14.37s\n",
      "        80           0.0536           0.0000           14.20s\n",
      "        90           0.0561           0.0000           14.15s\n",
      "       100           0.0514           0.0000           14.08s\n",
      "       200           0.0513           0.0000           12.83s\n",
      "       300           0.0462           0.0000           11.62s\n",
      "       400           0.0422           0.0000           10.37s\n",
      "       500           0.0465           0.0000            9.06s\n",
      "       600           0.0443           0.0000            7.73s\n",
      "       700           0.0427           0.0000            6.39s\n",
      "       800           0.0382           0.0000            5.01s\n",
      "       900           0.0362           0.0000            3.63s\n",
      "      1000           0.0385           0.0000            2.24s\n",
      "Final quality is:\n",
      "  - precision = 0.777778;\n",
      "  - recall    = 0.350000;\n",
      "  - F1        = 0.482759;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cls, threshold = train_gradboost(X_train, y_train, random_state=42)\n",
    "evaluate_classifier(X_test, y_test, cls, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2825
    },
    "colab_type": "code",
    "id": "eofAIEK2N730",
    "outputId": "f00bd768-9043-473a-9c06-c76f4a5118b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best ROC-AUC is 0.995353.\n",
      "Best C is 995.866336.\n",
      "\n",
      "Best threshold is 0.2623.\n",
      "Best F1 is 0.508475.\n",
      "\n",
      "Final quality is:\n",
      "  - precision = 0.888889;\n",
      "  - recall    = 0.400000;\n",
      "  - F1        = 0.551724;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cls, threshold = train_logreg(X_train, y_train, random_state=42)\n",
    "evaluate_classifier(X_test, y_test, cls, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z1vR4KgBqAOY"
   },
   "source": [
    "Открытие обучающего набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0osA3CuIP6fZ"
   },
   "outputs": [],
   "source": [
    "def rnn_read_training_data(file_name: str) -> List[np.ndarray]:\n",
    "    if not os.path.isfile(file_name):\n",
    "        raise ValueError('File `{0}` does not exist!'.format(file_name))\n",
    "    true_header = ['id', 'cycle', 's1', 's10', 's11', 's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's2',\n",
    "                   's20', 's21', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 'setting1', 'setting2']\n",
    "    X = []\n",
    "    loaded_header = None\n",
    "    line_idx = 1\n",
    "    cycle = 0\n",
    "    engine = None\n",
    "    new_X = []\n",
    "    with codecs.open(file_name, mode='r', encoding='utf-8', errors='ignore') as fp:\n",
    "        reader = csv.reader(fp, quotechar='\"', delimiter=';')\n",
    "        for row in reader:\n",
    "            prep = list(map(lambda it: it.strip(), row))\n",
    "            if len(prep) > 0:\n",
    "                err_msg = 'File `{0}`: line {1} is wrong!'.format(file_name, line_idx)\n",
    "                if loaded_header is None:\n",
    "                    loaded_header = copy.copy(prep)\n",
    "                    if loaded_header != true_header:\n",
    "                        raise ValueError(err_msg)\n",
    "                else:\n",
    "                    if len(prep) != len(loaded_header):\n",
    "                        raise ValueError(err_msg)\n",
    "                    if not prep[0].startswith('Engine_'):\n",
    "                        raise ValueError(err_msg)\n",
    "                    new_cycle = int(prep[1])\n",
    "                    if engine is None:\n",
    "                        engine = prep[0]\n",
    "                        cycle = 1\n",
    "                    else:\n",
    "                        if engine == prep[0]:\n",
    "                            cycle += 1\n",
    "                        else:\n",
    "                            engine = prep[0]\n",
    "                            cycle = 1\n",
    "                            if len(new_X) > 0:\n",
    "                                X.append(np.array(new_X, dtype=np.float64))\n",
    "                                new_X = []\n",
    "                    if cycle != new_cycle:\n",
    "                        raise ValueError(err_msg)\n",
    "                    new_X.append([float(val.replace(',', '.')) for val in prep[2:]])\n",
    "            line_idx += 1\n",
    "    if len(new_X) > 0:\n",
    "        X.append(np.array(new_X, dtype=np.float64))\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7lOK9vIgp9Ao"
   },
   "source": [
    "Открытие тестового набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y50s0SESSlD1"
   },
   "outputs": [],
   "source": [
    "\n",
    "def rnn_read_test_data(file_name: str) -> List[np.ndarray]:\n",
    "    if not os.path.isfile(file_name):\n",
    "        raise ValueError('File `{0}` does not exist!'.format(file_name))\n",
    "    true_header = ['id', 'cycle', 's1', 's10', 's11', 's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's2',\n",
    "                   's20', 's21', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 'setting1', 'setting2', 'Brake']\n",
    "    X = []\n",
    "    new_X = []\n",
    "    loaded_header = None\n",
    "    line_idx = 1\n",
    "    cycle = 0\n",
    "    engine = None\n",
    "    with codecs.open(file_name, mode='r', encoding='utf-8', errors='ignore') as fp:\n",
    "        reader = csv.reader(fp, quotechar='\"', delimiter =';')\n",
    "        for row in reader:\n",
    "            prep = list(map(lambda it: it.strip(), row))\n",
    "            if len(prep) > 0:\n",
    "                err_msg = 'File `{0}`: line {1} is wrong!'.format(file_name, line_idx)\n",
    "                if loaded_header is None:\n",
    "                    loaded_header = copy.copy(prep)\n",
    "                    if loaded_header != true_header:\n",
    "                        raise ValueError(err_msg)\n",
    "                else:\n",
    "                    if len(prep) != len(loaded_header):\n",
    "                        raise ValueError(err_msg)\n",
    "                    if not prep[0].startswith('Engine_'):\n",
    "                        raise ValueError(err_msg)\n",
    "                    new_cycle = int(prep[1])\n",
    "                    if engine is None:\n",
    "                        engine = prep[0]\n",
    "                        cycle = 1\n",
    "                    else:\n",
    "                        if engine == prep[0]:\n",
    "                            cycle += 1\n",
    "                        else:\n",
    "                            engine = prep[0]\n",
    "                            if len(new_X) > 0:\n",
    "                                X.append(np.array(new_X, dtype=np.float64))\n",
    "                                new_X = []\n",
    "                            cycle = 1\n",
    "                    if cycle != new_cycle:\n",
    "                        raise ValueError(err_msg)\n",
    "                    new_X.append([float(val.replace(',', '.')) for val in prep[2:-1]])\n",
    "            line_idx += 1\n",
    "    if len(new_X) > 0:\n",
    "        X.append(np.array(new_X, dtype=np.float64))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3l7XYTz8St7H"
   },
   "outputs": [],
   "source": [
    "def rnn_find_best_threshold(y_true: np.ndarray, predicted_probas: np.ndarray) -> float:\n",
    "    best_threshold = 1e-4\n",
    "    y_pred = np.asarray(predicted_probas >= best_threshold, dtype=np.int32)\n",
    "    best_f1 = f1_score(y_true, y_pred)\n",
    "    threshold = best_threshold + 1e-4\n",
    "    del y_pred\n",
    "    while threshold <= 1.0:\n",
    "        y_pred = np.asarray(predicted_probas >= threshold, dtype=np.int32)\n",
    "        new_f1 = f1_score(y_true, y_pred)\n",
    "        if new_f1 > best_f1:\n",
    "            best_threshold = threshold\n",
    "            best_f1 = new_f1\n",
    "        del y_pred\n",
    "        threshold += 1e-4\n",
    "    print('Best threshold is {0:.4f}.'.format(best_threshold))\n",
    "    print('Best F1 is {0:.6f}.'.format(best_f1))\n",
    "    return best_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "70ClWio3p6Uv"
   },
   "source": [
    "Обучение RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5YzdSlLjSybo"
   },
   "outputs": [],
   "source": [
    "def train_rnn(X: List[np.ndarray], n_sequence_size: int, recurrent_layer_size: int,\n",
    "              random_state: int) -> Tuple[Pipeline, Model, float]:\n",
    "    min_sequence_size = min([len(cur) for cur in X])\n",
    "    if n_sequence_size >= min_sequence_size:\n",
    "        raise ValueError('`{0}` is too large value for `n_sequence_size`! It must be less than {1}.'.format(\n",
    "            n_sequence_size, min_sequence_size))\n",
    "    indices = np.arange(0, len(X), 1, dtype=np.int32)\n",
    "    np.random.shuffle(indices)\n",
    "    X_train = []\n",
    "    X_val = []\n",
    "    n_test = int(round(0.1 * len(X)))\n",
    "    if n_test < 2:\n",
    "        raise ValueError('{0} is very small value for `X`!'.format(len(X)))\n",
    "    for idx in indices[:n_test]:\n",
    "        X_val.append(X[idx])\n",
    "    for idx in indices[n_test:]:\n",
    "        X_train.append(X[idx])\n",
    "    preprocessor = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler(with_mean=True, with_std=False, copy=True)),\n",
    "        ('selector', VarianceThreshold(threshold=1e-6)),\n",
    "        ('pca', PCA(copy=True, whiten=True, random_state=random_state)),\n",
    "    ])\n",
    "    preprocessor.fit(np.vstack(X_train))\n",
    "    X_train_ = []\n",
    "    y_train_ = []\n",
    "    for cur in X_train:\n",
    "        prep = preprocessor.transform(cur)\n",
    "        for idx in range(prep.shape[0] - n_sequence_size):\n",
    "            X_train_.append(prep[idx:(idx + n_sequence_size)])\n",
    "            y_train_.append(0)\n",
    "        idx = prep.shape[0] - n_sequence_size\n",
    "        X_train_.append(prep[idx:(idx + n_sequence_size)])\n",
    "        y_train_.append(1)\n",
    "        del prep\n",
    "    X_train_ = np.array(X_train_, dtype=np.float32)\n",
    "    y_train_ = np.array(y_train_, dtype=np.int32)\n",
    "    print('Sequence size is {0}.'.format(X_train_.shape[1]))\n",
    "    print('Feature vector size is {0}.'.format(X_train_.shape[2]))\n",
    "    print('Number of sequences in the training set is {0}.'.format(X_train_.shape[0]))\n",
    "    print('Number of positive samples in the training set is {0}.'.format(int(sum(y_train_))))\n",
    "    X_val_ = []\n",
    "    y_val_ = []\n",
    "    for cur in X_val:\n",
    "        prep = preprocessor.transform(cur)\n",
    "        for idx in range(prep.shape[0] - n_sequence_size):\n",
    "            X_val_.append(prep[idx:(idx + n_sequence_size)])\n",
    "            y_val_.append(0)\n",
    "        idx = prep.shape[0] - n_sequence_size\n",
    "        X_val_.append(prep[idx:(idx + n_sequence_size)])\n",
    "        y_val_.append(1)\n",
    "        del prep\n",
    "    X_val_ = np.array(X_val_, dtype=np.float32)\n",
    "    y_val_ = np.array(y_val_, dtype=np.int32)\n",
    "    print('Number of sequences in the validation set is {0}.'.format(X_val_.shape[0]))\n",
    "    print('Number of positive samples in the validation set is {0}.'.format(int(sum(y_val_))))\n",
    "    print('')\n",
    "    assert X_train_.shape[1] == n_sequence_size\n",
    "    assert X_train_.shape[1] == X_val_.shape[1]\n",
    "    assert X_train_.shape[2] == X_val_.shape[2]\n",
    "    input_layer = Input(shape=(n_sequence_size, X_train_.shape[2]), name='NormalizedSensors')\n",
    "    lstm_layer = GRU(units=recurrent_layer_size, kernel_initializer=glorot_uniform(seed=random_state),\n",
    "                     name='RNN')(input_layer)\n",
    "    output_layer = Dense(units=1, activation='sigmoid', kernel_initializer=glorot_uniform(seed=random_state),\n",
    "                         name='Output')(lstm_layer)\n",
    "    nn = Model(input_layer, output_layer)\n",
    "    nn.compile(optimizer=RMSprop(lr=1e-2, clipnorm=5.0), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    nn.summary(line_length=100)\n",
    "    batch_size = 256\n",
    "    n_batches = int(np.ceil(X_train_.shape[0] / float(batch_size)))\n",
    "    bounds_of_batches = [(idx * batch_size, min((idx + 1) * batch_size, X_train_.shape[0])) for idx in range(n_batches)]\n",
    "    best_roc_auc = None\n",
    "    n_iters_without_improving = 1\n",
    "    nn_file_name = tempfile.NamedTemporaryFile().name\n",
    "    try:\n",
    "        for epoch_idx in range(200):\n",
    "            random.shuffle(bounds_of_batches)\n",
    "            for batch_start, batch_end in bounds_of_batches:\n",
    "                nn.train_on_batch(X_train_[batch_start:batch_end], y_train_[batch_start:batch_end])\n",
    "            y_pred = nn.predict(X_val_, batch_size=batch_size)\n",
    "            val_roc_auc = roc_auc_score(y_val_, y_pred)\n",
    "            print('Epoch {0}: val. ROC-AUC = {1:.6f}'.format(epoch_idx + 1, val_roc_auc))\n",
    "            if best_roc_auc is None:\n",
    "                best_roc_auc = val_roc_auc\n",
    "                n_iters_without_improving = 1\n",
    "                nn.save(nn_file_name)\n",
    "            else:\n",
    "                if val_roc_auc > best_roc_auc:\n",
    "                    n_iters_without_improving = 1\n",
    "                    best_roc_auc = val_roc_auc\n",
    "                    nn.save(nn_file_name)\n",
    "                else:\n",
    "                    n_iters_without_improving += 1\n",
    "            if n_iters_without_improving > 7:\n",
    "                print('Early stopping...')\n",
    "                break\n",
    "        if os.path.isfile(nn_file_name):\n",
    "            nn = load_model(nn_file_name)\n",
    "    finally:\n",
    "        if os.path.isfile(nn_file_name):\n",
    "            os.remove(nn_file_name)\n",
    "    threshold = rnn_find_best_threshold(y_val_, nn.predict(X_val_, batch_size=batch_size))\n",
    "    print('')\n",
    "    return preprocessor, nn, threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VQAunQHQp4VU"
   },
   "source": [
    "Функция для отображения результата"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WWCt4HonS5eO"
   },
   "outputs": [],
   "source": [
    "def evaluate_rnn(X: List[np.ndarray], n_sequence_size: int, preprocessor: Pipeline, classifier: Model,\n",
    "                        threshold: float):\n",
    "    min_sequence_size = min([len(cur) for cur in X])\n",
    "    if n_sequence_size >= min_sequence_size:\n",
    "        raise ValueError('`{0}` is too large value for `n_sequence_size`! It must be less than {1}.'.format(\n",
    "            n_sequence_size, min_sequence_size))\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for cur in X:\n",
    "        prep = preprocessor.transform(cur)\n",
    "        for idx in range(prep.shape[0] - n_sequence_size):\n",
    "            X_test.append(prep[idx:(idx + n_sequence_size)])\n",
    "            y_test.append(0)\n",
    "        idx = prep.shape[0] - n_sequence_size\n",
    "        X_test.append(prep[idx:(idx + n_sequence_size)])\n",
    "        y_test.append(1)\n",
    "        del prep\n",
    "    X_test = np.array(X_test, dtype=np.float32)\n",
    "    y_test = np.array(y_test, dtype=np.int32)\n",
    "    print('Number of sequences in the test set is {0}.'.format(X_test.shape[0]))\n",
    "    print('')\n",
    "    y_pred = np.asarray(classifier.predict(X_test, batch_size=128) >= threshold, dtype=np.int32)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print('Final quality is:')\n",
    "    print('  - precision = {0:8.6f};'.format(precision))\n",
    "    print('  - recall    = {0:8.6f};'.format(recall))\n",
    "    print('  - F1        = {0:8.6f};'.format(f1))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 782
    },
    "colab_type": "code",
    "id": "7bY8zJokS9xU",
    "outputId": "d6b57a4f-3031-47d5-ed7f-b047f64e6fbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence size is 50.\n",
      "Feature vector size is 16.\n",
      "Number of sequences in the training set is 11124.\n",
      "Number of positive samples in the training set is 72.\n",
      "Number of sequences in the validation set is 1094.\n",
      "Number of positive samples in the validation set is 8.\n",
      "\n",
      "WARNING:tensorflow:From /home/user/tf_bayesian/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                                 Output Shape                            Param #        \n",
      "====================================================================================================\n",
      "NormalizedSensors (InputLayer)               (None, 50, 16)                          0              \n",
      "____________________________________________________________________________________________________\n",
      "RNN (GRU)                                    (None, 10)                              810            \n",
      "____________________________________________________________________________________________________\n",
      "Output (Dense)                               (None, 1)                               11             \n",
      "====================================================================================================\n",
      "Total params: 821\n",
      "Trainable params: 821\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /home/user/tf_bayesian/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1: val. ROC-AUC = 0.968808\n",
      "Epoch 2: val. ROC-AUC = 0.980663\n",
      "Epoch 3: val. ROC-AUC = 0.991252\n",
      "Epoch 4: val. ROC-AUC = 0.987914\n",
      "Epoch 5: val. ROC-AUC = 0.991598\n",
      "Epoch 6: val. ROC-AUC = 0.992288\n",
      "Epoch 7: val. ROC-AUC = 0.987799\n",
      "Epoch 8: val. ROC-AUC = 0.987224\n",
      "Epoch 9: val. ROC-AUC = 0.989065\n",
      "Epoch 10: val. ROC-AUC = 0.986648\n",
      "Epoch 11: val. ROC-AUC = 0.987569\n",
      "Epoch 12: val. ROC-AUC = 0.989986\n",
      "Epoch 13: val. ROC-AUC = 0.987914\n",
      "Early stopping...\n",
      "Best threshold is 0.2210.\n",
      "Best F1 is 0.500000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "train_file_name = 'Data_80.csv'\n",
    "test_file_name = 'Data_Add_20.csv'\n",
    "n_history = 50\n",
    "rnn_units_number = 10\n",
    "X_train = rnn_read_training_data(os.path.normpath(train_file_name))\n",
    "X_test = rnn_read_test_data(os.path.normpath(test_file_name))\n",
    "preprocessor, classifier, threshold = train_rnn(X_train, n_sequence_size=n_history, random_state=42,\n",
    "                                                    recurrent_layer_size=rnn_units_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "9gjg52FAT0C0",
    "outputId": "011695fb-3acc-48b2-bc25-778d33eb3d78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences in the test set is 3071.\n",
      "\n",
      "Final quality is:\n",
      "  - precision = 0.500000;\n",
      "  - recall    = 0.250000;\n",
      "  - F1        = 0.333333;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_rnn(X_test, n_sequence_size=n_history, preprocessor=preprocessor, classifier=classifier,\n",
    "                        threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "sap.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
